{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling, evaluation and MVP dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "Create and train XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs\n",
    "`output/nb2_market_index_with_historical_and_features.feather`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes/comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import hvplot.pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "preprocessed_df = pd.read_feather('../output/nb2_market_index_with_historical_and_features.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DataFrame\n",
    "model_df = preprocessed_df.dropna().copy().reset_index().rename(columns={\"index\": \"Date\"})\n",
    "model_df[\"Date\"] = pd.to_datetime(model_df[\"Date\"])\n",
    "model_df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Features & Target\n",
    "feature_cols = [\"Has_Event\", \"SMA_4\", \"RSI_4\", \"MACD\", \"MACD_Signal\", \"BB_Width\"]\n",
    "X = model_df[feature_cols]\n",
    "y = model_df[\"Sentiment_Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based Train/Test Split\n",
    "split_index = int(len(model_df) * 0.8)\n",
    "train_df = model_df.iloc[:split_index]\n",
    "test_df = model_df.iloc[split_index:]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df[\"Sentiment_Label\"]\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df[\"Sentiment_Label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scaler\n",
    "joblib.dump(scaler, '../output/scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "model = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "joblib.dump(model, \"../output/xgb_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Test Set Only\n",
    "y_pred = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Predictions to model_df (only for test part)\n",
    "model_df[\"Predicted_Label\"] = np.nan  # initialize with NaNs\n",
    "model_df.loc[split_index:, \"Predicted_Label\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities (confidence that label is bullish)\n",
    "y_proba = model.predict_proba(X_test_scaled)[:, 1]  # Probability of class 1 (bullish)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in the test portion of model_df\n",
    "model_df.loc[split_index:, \"Confidence_Score\"] = y_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark correctness\n",
    "model_df[\"Correct\"] = np.nan\n",
    "model_df.loc[split_index:, \"Correct\"] = (\n",
    "    model_df.loc[split_index:, \"Predicted_Label\"] == model_df.loc[split_index:, \"Sentiment_Label\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy & Classification Report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy_text = f\"\"\"<span style=\"color:green; font-weight:bold; font-size:16px;\">\n",
    "âœ… Model Accuracy (on unseen data): {accuracy:.2%}\n",
    "</span>\"\"\"\n",
    "report = classification_report(y_test, y_pred, target_names=[\"Bearish\", \"Bullish\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict next week\n",
    "# Get the most recent week of features\n",
    "# Check the date range set in notebook 1\n",
    "X_next = preprocessed_df.dropna().copy().tail(1)[feature_cols]\n",
    "X_next_scaled = scaler.transform(X_next)\n",
    "\n",
    "# Predict next week\n",
    "next_label = model.predict(X_next_scaled)[0]\n",
    "next_proba = model.predict_proba(X_next_scaled)[0][1]  # Probability of bullish\n",
    "\n",
    "# Format\n",
    "label_str = \"ðŸ“ˆ Bullish\" if next_label == 1 else \"ðŸ“‰ Bearish\"\n",
    "confidence_str = f\"{next_proba:.2%}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
